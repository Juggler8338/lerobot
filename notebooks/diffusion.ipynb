{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e8dca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "配置加载完成。动作维度: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr1/home/s125mdg55_01/miniforge3/envs/lerobot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %% [1] Imports and Mock Configuration\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import einops\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "# 检查是否安装了必要的库\n",
    "try:\n",
    "    import diffusers\n",
    "except ImportError:\n",
    "    print(\"请安装 diffusers: pip install diffusers\")\n",
    "\n",
    "# --- 模拟 Lerobot 的辅助函数 (为了让代码独立运行) ---\n",
    "def get_output_shape(model, image_dim):\n",
    "    return model(torch.rand(*(image_dim))).data.shape\n",
    "\n",
    "# --- 模拟配置类 ---\n",
    "@dataclass\n",
    "class MockConfig:\n",
    "    # 视觉相关\n",
    "    vision_backbone: str = \"resnet18\"\n",
    "    pretrained_backbone_weights: str = None\n",
    "    crop_shape: Tuple[int, int] = (84, 84)\n",
    "    crop_is_random: bool = False\n",
    "    use_group_norm: bool = True\n",
    "    spatial_softmax_num_keypoints: int = 32\n",
    "    \n",
    "    # 维度相关\n",
    "    image_features: dict = None # 下面初始化\n",
    "    action_feature: torch.Tensor = torch.zeros(14) # 假设动作维度 14\n",
    "    n_obs_steps: int = 2  # 观察历史长度\n",
    "    \n",
    "    # U-Net 结构\n",
    "    down_dims: Tuple[int, ...] = (128, 256, 512) # 简化一点以便测试\n",
    "    kernel_size: int = 5\n",
    "    n_groups: int = 8\n",
    "    diffusion_step_embed_dim: int = 128\n",
    "    use_film_scale_modulation: bool = True\n",
    "    \n",
    "    # 扩散参数\n",
    "    num_train_timesteps: int = 100\n",
    "    beta_start: float = 0.0001\n",
    "    beta_end: float = 0.02\n",
    "    beta_schedule: str = \"squaredcos_cap_v2\"\n",
    "    prediction_type: str = \"epsilon\"\n",
    "    clip_sample: bool = True\n",
    "    clip_sample_range: float = 1.0\n",
    "\n",
    "# 初始化配置\n",
    "config = MockConfig()\n",
    "# 模拟输入图片格式: (Channel, Height, Width)\n",
    "config.image_features = {\"camera_0\": torch.zeros(3, 96, 96)} \n",
    "\n",
    "print(\"配置加载完成。动作维度:\", config.action_feature.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2f7b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入特征图: torch.Size([2, 512, 10, 10])\n",
      "输出关键点: torch.Size([2, 32, 2]) (Batch, Keypoints, 2)\n"
     ]
    }
   ],
   "source": [
    "# %% [2] Spatial Softmax\n",
    "class SpatialSoftmax(nn.Module):\n",
    "    def __init__(self, input_shape, num_kp=None):\n",
    "        super().__init__()\n",
    "        self._in_c, self._in_h, self._in_w = input_shape\n",
    "        \n",
    "        if num_kp is not None:\n",
    "            self.nets = torch.nn.Conv2d(self._in_c, num_kp, kernel_size=1)\n",
    "            self._out_c = num_kp\n",
    "        else:\n",
    "            self.nets = None\n",
    "            self._out_c = self._in_c\n",
    "\n",
    "        pos_x, pos_y = torch.meshgrid(\n",
    "            torch.linspace(-1.0, 1.0, self._in_w), \n",
    "            torch.linspace(-1.0, 1.0, self._in_h),\n",
    "            indexing='xy'\n",
    "        )\n",
    "        pos_x = pos_x.reshape(self._in_h * self._in_w, 1)\n",
    "        pos_y = pos_y.reshape(self._in_h * self._in_w, 1)\n",
    "        self.register_buffer(\"pos_grid\", torch.cat([pos_x, pos_y], dim=1))\n",
    "\n",
    "    def forward(self, features):\n",
    "        if self.nets is not None:\n",
    "            features = self.nets(features)\n",
    "        \n",
    "        # [B, K, H, W] -> [B * K, H * W]\n",
    "        features = features.reshape(-1, self._in_h * self._in_w)\n",
    "        attention = F.softmax(features, dim=-1)\n",
    "        # [B * K, H * W] x [H * W, 2] -> [B * K, 2]\n",
    "        expected_xy = attention @ self.pos_grid\n",
    "        feature_keypoints = expected_xy.view(-1, self._out_c, 2)\n",
    "        return feature_keypoints\n",
    "\n",
    "# --- 验证 ---\n",
    "# 假设 ResNet 输出特征图大小为 (Batch=2, Channel=512, H=10, W=10)\n",
    "dummy_feature_map = torch.randn(2, 512, 10, 10)\n",
    "pooler = SpatialSoftmax(input_shape=(512, 10, 10), num_kp=32)\n",
    "output_kp = pooler(dummy_feature_map)\n",
    "\n",
    "print(f\"输入特征图: {dummy_feature_map.shape}\")\n",
    "print(f\"输出关键点: {output_kp.shape} (Batch, Keypoints, 2)\")\n",
    "assert output_kp.shape == (2, 32, 2), \"Spatial Softmax 输出维度错误！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "382011df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入图片: torch.Size([2, 3, 96, 96])\n",
      "编码向量: torch.Size([2, 64])\n"
     ]
    }
   ],
   "source": [
    "# %% [3] Vision Encoder\n",
    "class DiffusionRgbEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # 1. 图像预处理 (Crop)\n",
    "        if config.crop_shape is not None:\n",
    "            self.do_crop = True\n",
    "            self.center_crop = torchvision.transforms.CenterCrop(config.crop_shape)\n",
    "        else:\n",
    "            self.do_crop = False\n",
    "\n",
    "        # 2. 加载 Backbone (ResNet18)\n",
    "        backbone_model = getattr(torchvision.models, config.vision_backbone)(weights=None) # 这里为了速度不下载权重\n",
    "        # 取掉最后的全连接层和Pooling层\n",
    "        self.backbone = nn.Sequential(*(list(backbone_model.children())[:-2]))\n",
    "        \n",
    "        # 3. 将 BatchNorm 替换为 GroupNorm (这对 Diffusion 训练稳定性很重要)\n",
    "        # (简化版：省略了递归替换函数 _replace_submodules 的完整实现，仅作演示)\n",
    "        # 在实际代码中，这里会遍历网络替换 BN 为 GN\n",
    "\n",
    "        # 4. 计算 Backbone 输出形状\n",
    "        dummy_input = torch.zeros(1, 3, *config.crop_shape)\n",
    "        with torch.no_grad():\n",
    "            feature_map_shape = self.backbone(dummy_input).shape[1:] # [C, H, W]\n",
    "\n",
    "        # 5. Pooling 和 投影\n",
    "        self.pool = SpatialSoftmax(feature_map_shape, num_kp=config.spatial_softmax_num_keypoints)\n",
    "        self.feature_dim = config.spatial_softmax_num_keypoints * 2\n",
    "        self.out = nn.Linear(self.feature_dim, self.feature_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.do_crop:\n",
    "            x = self.center_crop(x) # 简化：只用 center crop\n",
    "        \n",
    "        x = self.backbone(x)      # [B, 512, H', W']\n",
    "        x = self.pool(x)          # [B, K, 2]\n",
    "        x = torch.flatten(x, start_dim=1) # [B, K*2]\n",
    "        x = self.relu(self.out(x))\n",
    "        return x\n",
    "\n",
    "# --- 验证 ---\n",
    "encoder = DiffusionRgbEncoder(config)\n",
    "# 假设输入 Batch=2 的图片\n",
    "dummy_img = torch.randn(2, 3, 96, 96) \n",
    "encoded_vec = encoder(dummy_img)\n",
    "\n",
    "print(f\"输入图片: {dummy_img.shape}\")\n",
    "print(f\"编码向量: {encoded_vec.shape}\")\n",
    "assert encoded_vec.shape == (2, 32*2), \"Visual Encoder 输出维度错误！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d52c78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResBlock 输入: torch.Size([2, 64, 16])\n",
      "ResBlock 输出: torch.Size([2, 128, 16])\n"
     ]
    }
   ],
   "source": [
    "# %% [4] U-Net Building Blocks\n",
    "class DiffusionConv1dBlock(nn.Module):\n",
    "    def __init__(self, inp_channels, out_channels, kernel_size, n_groups=8):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv1d(inp_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
    "            nn.GroupNorm(n_groups, out_channels),\n",
    "            nn.Mish(),\n",
    "        )\n",
    "    def forward(self, x): return self.block(x)\n",
    "\n",
    "class DiffusionConditionalResidualBlock1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, cond_dim, kernel_size=3, n_groups=8, use_film_scale_modulation=True):\n",
    "        super().__init__()\n",
    "        self.use_film_scale_modulation = use_film_scale_modulation\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.conv1 = DiffusionConv1dBlock(in_channels, out_channels, kernel_size, n_groups=n_groups)\n",
    "        \n",
    "        # FiLM: 将条件向量映射为 Scale 和 Bias\n",
    "        cond_channels = out_channels * 2 if use_film_scale_modulation else out_channels\n",
    "        self.cond_encoder = nn.Sequential(nn.Mish(), nn.Linear(cond_dim, cond_channels))\n",
    "        \n",
    "        self.conv2 = DiffusionConv1dBlock(out_channels, out_channels, kernel_size, n_groups=n_groups)\n",
    "        self.residual_conv = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x, cond):\n",
    "        out = self.conv1(x)\n",
    "        \n",
    "        # FiLM 调制逻辑\n",
    "        # cond: [Batch, Cond_Dim] -> [Batch, Out_Channels * 2] -> [Batch, Out_Channels * 2, 1]\n",
    "        cond_embed = self.cond_encoder(cond).unsqueeze(-1) \n",
    "        \n",
    "        if self.use_film_scale_modulation:\n",
    "            scale, bias = torch.split(cond_embed, self.out_channels, dim=1)\n",
    "            out = scale * out + bias # 核心：特征调制\n",
    "        else:\n",
    "            out = out + cond_embed\n",
    "            \n",
    "        out = self.conv2(out)\n",
    "        out = out + self.residual_conv(x)\n",
    "        return out\n",
    "\n",
    "# --- 验证 ---\n",
    "# 假设：Batch=2, 特征通道=64, 序列长度(Horizon)=16\n",
    "dummy_feat = torch.randn(2, 64, 16)\n",
    "# 假设：条件向量维度=128 (来自 ResNet + TimeEmbedding)\n",
    "dummy_cond = torch.randn(2, 128)\n",
    "\n",
    "block = DiffusionConditionalResidualBlock1d(in_channels=64, out_channels=128, cond_dim=128)\n",
    "out_block = block(dummy_feat, dummy_cond)\n",
    "\n",
    "print(f\"ResBlock 输入: {dummy_feat.shape}\")\n",
    "print(f\"ResBlock 输出: {out_block.shape}\")\n",
    "assert out_block.shape == (2, 128, 16), \"ResBlock 维度变换错误！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d9eea46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 开始验证 U-Net ---\n",
      "输入形状: torch.Size([2, 16, 14])\n",
      "输出形状: torch.Size([2, 16, 14])\n",
      "✅ 验证成功：输入输出形状完全一致 (16 -> 16)！\n"
     ]
    }
   ],
   "source": [
    "# %% [5] Conditional U-Net (Refined & Annotated)\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import einops\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 辅助模块：位置编码\n",
    "# -----------------------------------------------------------------------------\n",
    "class DiffusionSinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x.unsqueeze(-1) * emb.unsqueeze(0)\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 核心模块：1D U-Net\n",
    "# -----------------------------------------------------------------------------\n",
    "class DiffusionConditionalUnet1d(nn.Module):\n",
    "    def __init__(self, config, global_cond_dim):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # 1. 时间步编码 (Timestep Embedding)\n",
    "        # 将一个数字 t (如 50) 映射为高维向量\n",
    "        self.diffusion_step_encoder = nn.Sequential(\n",
    "            DiffusionSinusoidalPosEmb(config.diffusion_step_embed_dim),\n",
    "            nn.Linear(config.diffusion_step_embed_dim, config.diffusion_step_embed_dim * 4),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(config.diffusion_step_embed_dim * 4, config.diffusion_step_embed_dim),\n",
    "        )\n",
    "        \n",
    "        # FiLM 条件维度 = 时间嵌入 + 视觉/状态条件\n",
    "        cond_dim = config.diffusion_step_embed_dim + global_cond_dim\n",
    "        \n",
    "        # ---------------------------------------------------------------------\n",
    "        # A. 构建 Encoder (下采样路径)\n",
    "        # ---------------------------------------------------------------------\n",
    "        # 结构定义: [(14, 128), (128, 256), (256, 512)]\n",
    "        in_out = [(config.action_feature.shape[0], config.down_dims[0])] + list(\n",
    "            zip(config.down_dims[:-1], config.down_dims[1:])\n",
    "        )\n",
    "\n",
    "        self.down_modules = nn.ModuleList([])\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            # 判断是否是 Encoder 的最后一层 (Bottleneck 前夕)\n",
    "            is_last = (ind >= len(in_out) - 1)\n",
    "            \n",
    "            self.down_modules.append(nn.ModuleList([\n",
    "                DiffusionConditionalResidualBlock1d(dim_in, dim_out, cond_dim),\n",
    "                DiffusionConditionalResidualBlock1d(dim_out, dim_out, cond_dim),\n",
    "                # 关键逻辑：除了最后一层，其他层都做 stride=2 的下采样\n",
    "                nn.Conv1d(dim_out, dim_out, 3, 2, 1) if not is_last else nn.Identity()\n",
    "            ]))\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # B. 构建 Mid (瓶颈层)\n",
    "        # ---------------------------------------------------------------------\n",
    "        mid_dim = config.down_dims[-1]\n",
    "        self.mid_modules = nn.ModuleList([\n",
    "            DiffusionConditionalResidualBlock1d(mid_dim, mid_dim, cond_dim),\n",
    "            DiffusionConditionalResidualBlock1d(mid_dim, mid_dim, cond_dim),\n",
    "        ])\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # C. 构建 Decoder (上采样路径)\n",
    "        # ---------------------------------------------------------------------\n",
    "        self.up_modules = nn.ModuleList([])\n",
    "        \n",
    "        # 倒序遍历 in_out: [(256, 512), (128, 256), (14, 128)]\n",
    "        # 注意：这里的 dim_orig_in/out 是指 Encoder 时的输入输出\n",
    "        for ind, (dim_orig_in, dim_orig_out) in enumerate(reversed(in_out)):\n",
    "            \n",
    "            # Decoder 输入维度 = Encoder 输出维度\n",
    "            dim_in = dim_orig_out\n",
    "            \n",
    "            # Decoder 输出维度 = Encoder 输入维度\n",
    "            # 特殊情况：Decoder 最后一层不应该输出 14 (动作维)，而是保持高维 (128)，\n",
    "            # 留给 Final Conv 去压缩。\n",
    "            is_last_layer = (ind == len(in_out) - 1)\n",
    "            dim_out = dim_orig_in if not is_last_layer else dim_orig_out\n",
    "            \n",
    "            # 关键逻辑：Decoder 除了最后一层，都需要上采样 (4->8, 8->16)\n",
    "            should_upsample = not is_last_layer\n",
    "            \n",
    "            self.up_modules.append(nn.ModuleList([\n",
    "                # dim_in * 2 是因为我们要拼接来自 Encoder 的 Skip Connection\n",
    "                DiffusionConditionalResidualBlock1d(dim_in * 2, dim_out, cond_dim),\n",
    "                DiffusionConditionalResidualBlock1d(dim_out, dim_out, cond_dim),\n",
    "                # 上采样层\n",
    "                nn.ConvTranspose1d(dim_out, dim_out, 4, 2, 1) if should_upsample else nn.Identity()\n",
    "            ]))\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # D. 输出层\n",
    "        # ---------------------------------------------------------------------\n",
    "        self.final_conv = nn.Sequential(\n",
    "            DiffusionConv1dBlock(config.down_dims[0], config.down_dims[0], kernel_size=5),\n",
    "            nn.Conv1d(config.down_dims[0], config.action_feature.shape[0], 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, timestep, global_cond):\n",
    "        \"\"\"\n",
    "        x: [Batch, Horizon, ActionDim] (例如 2, 16, 14)\n",
    "        \"\"\"\n",
    "        # 1. 维度调整: (B, T, D) -> (B, D, T) 以适应 Conv1d\n",
    "        x = einops.rearrange(x, \"b t d -> b d t\")\n",
    "        \n",
    "        # 2. 准备条件向量\n",
    "        timesteps_embed = self.diffusion_step_encoder(timestep)\n",
    "        # 拼接时间信息和视觉信息\n",
    "        global_feature = torch.cat([timesteps_embed, global_cond], axis=-1)\n",
    "        \n",
    "        # 3. --- Encoder Forward ---\n",
    "        encoder_skip_features = []\n",
    "        for resnet1, resnet2, downsample in self.down_modules:\n",
    "            x = resnet1(x, global_feature)\n",
    "            x = resnet2(x, global_feature)\n",
    "            # 重要：先保存 Skip Connection，再下采样\n",
    "            # 举例 Layer 0: 输入长度 16，这里保存长度 16 的特征\n",
    "            encoder_skip_features.append(x) \n",
    "            x = downsample(x) # 长度变为 8\n",
    "            \n",
    "        # 4. --- Mid Forward ---\n",
    "        for mid_mod in self.mid_modules:\n",
    "            x = mid_mod(x, global_feature)\n",
    "            \n",
    "        # 5. --- Decoder Forward ---\n",
    "        for resnet1, resnet2, upsample in self.up_modules:\n",
    "            # 取出对应的 Skip Connection\n",
    "            skip = encoder_skip_features.pop()\n",
    "            \n",
    "            # 安全检查：防止因 padding 导致 1 像素的误差\n",
    "            if x.shape[-1] != skip.shape[-1]:\n",
    "                x = F.interpolate(x, size=skip.shape[-1], mode='nearest')\n",
    "                \n",
    "            # 拼接: [Batch, C_dec, T] + [Batch, C_skip, T] -> [Batch, C_dec*2, T]\n",
    "            x = torch.cat((x, skip), dim=1) \n",
    "            \n",
    "            x = resnet1(x, global_feature)\n",
    "            x = resnet2(x, global_feature)\n",
    "            x = upsample(x) # 长度翻倍 (4->8, 8->16)\n",
    "            \n",
    "        # 6. Final Output\n",
    "        x = self.final_conv(x)\n",
    "        # 维度还原: (B, D, T) -> (B, T, D)\n",
    "        x = einops.rearrange(x, \"b d t -> b t d\")\n",
    "        return x\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 验证代码\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"--- 开始验证 U-Net ---\")\n",
    "config_test = MockConfig()\n",
    "config_test.action_feature = torch.zeros(14) \n",
    "config_test.down_dims = (128, 256, 512)\n",
    "horizon = 16 \n",
    "\n",
    "unet = DiffusionConditionalUnet1d(config_test, global_cond_dim=64)\n",
    "\n",
    "# 模拟输入\n",
    "dummy_x = torch.randn(2, horizon, 14)\n",
    "dummy_t = torch.tensor([10, 20])\n",
    "dummy_c = torch.randn(2, 64)\n",
    "\n",
    "# 运行\n",
    "out = unet(dummy_x, dummy_t, dummy_c)\n",
    "\n",
    "print(f\"输入形状: {dummy_x.shape}\")\n",
    "print(f\"输出形状: {out.shape}\")\n",
    "\n",
    "if out.shape == dummy_x.shape:\n",
    "    print(\"✅ 验证成功：输入输出形状完全一致 (16 -> 16)！\")\n",
    "else:\n",
    "    print(\"❌ 验证失败：形状不匹配。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
